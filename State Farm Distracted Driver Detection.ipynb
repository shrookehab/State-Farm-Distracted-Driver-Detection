{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"! pip install tf-explain","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:24.797485Z","iopub.execute_input":"2022-07-09T17:57:24.798142Z","iopub.status.idle":"2022-07-09T17:57:37.018938Z","shell.execute_reply.started":"2022-07-09T17:57:24.798106Z","shell.execute_reply":"2022-07-09T17:57:37.017768Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport pickle\n\n\nimport skimage\nfrom skimage.feature import hog, canny\nfrom skimage.filters import sobel\nfrom skimage import color\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n\nfrom keras import layers\nimport keras.backend as K\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing import image\nfrom tensorflow.keras.utils import load_img, img_to_array\nfrom keras.layers import Input, Dense, Activation, Dropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.applications.vgg19 import preprocess_input\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications import ResNet50\nfrom tf_explain.core.activations import ExtractActivations\nfrom tf_explain.core.grad_cam import GradCAM\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.data_utils import get_file\nfrom keras.utils.np_utils import to_categorical\n\nfrom PIL import Image\nfrom tqdm import tqdm\nimport random as rnd\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:37.021405Z","iopub.execute_input":"2022-07-09T17:57:37.021799Z","iopub.status.idle":"2022-07-09T17:57:37.090326Z","shell.execute_reply.started":"2022-07-09T17:57:37.021759Z","shell.execute_reply":"2022-07-09T17:57:37.089308Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ntrain_df['path'] = '../input/state-farm-distracted-driver-detection/imgs/train/' + train_df['classname'] + '/' + train_df['img']\npre_df = pd.read_csv('../input/state-farm-distracted-driver-detection/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:46.570694Z","iopub.execute_input":"2022-07-09T17:57:46.571055Z","iopub.status.idle":"2022-07-09T17:57:46.776061Z","shell.execute_reply.started":"2022-07-09T17:57:46.571024Z","shell.execute_reply":"2022-07-09T17:57:46.774960Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"classes = {\n    'c0': 'normal driving',\n    'c1': 'texting - right',\n    'c2': 'talking on the phone - right',\n    'c3': 'texting - left',\n    'c4': 'talking on the phone - left',\n    'c5': 'operating the radio',\n    'c6': 'drinking',\n    'c7': 'reaching behind',\n    'c8': 'hair and makeup',\n    'c9': 'talking to passenger'\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:47.028704Z","iopub.execute_input":"2022-07-09T17:57:47.029560Z","iopub.status.idle":"2022-07-09T17:57:47.036849Z","shell.execute_reply.started":"2022-07-09T17:57:47.029524Z","shell.execute_reply":"2022-07-09T17:57:47.033901Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df.keys()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:47.529305Z","iopub.execute_input":"2022-07-09T17:57:47.530036Z","iopub.status.idle":"2022-07-09T17:57:47.541593Z","shell.execute_reply.started":"2022-07-09T17:57:47.529990Z","shell.execute_reply":"2022-07-09T17:57:47.540311Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:47.922630Z","iopub.execute_input":"2022-07-09T17:57:47.923555Z","iopub.status.idle":"2022-07-09T17:57:47.941557Z","shell.execute_reply.started":"2022-07-09T17:57:47.923484Z","shell.execute_reply":"2022-07-09T17:57:47.940475Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df['classname'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:48.210664Z","iopub.execute_input":"2022-07-09T17:57:48.211573Z","iopub.status.idle":"2022-07-09T17:57:48.226834Z","shell.execute_reply.started":"2022-07-09T17:57:48.211538Z","shell.execute_reply":"2022-07-09T17:57:48.225811Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_df.isna().sum()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:48.568760Z","iopub.execute_input":"2022-07-09T17:57:48.569386Z","iopub.status.idle":"2022-07-09T17:57:48.591102Z","shell.execute_reply.started":"2022-07-09T17:57:48.569350Z","shell.execute_reply":"2022-07-09T17:57:48.590058Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\nfor idx, id in enumerate(train_df['classname'].unique()):\n    plt.subplot(3,4,idx+1)\n    plt.imshow(plt.imread(train_df[train_df['classname'] == id]['path'].values[0]))\n    plt.title(classes[id])\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:49.217980Z","iopub.execute_input":"2022-07-09T17:57:49.218325Z","iopub.status.idle":"2022-07-09T17:57:50.711689Z","shell.execute_reply.started":"2022-07-09T17:57:49.218294Z","shell.execute_reply":"2022-07-09T17:57:50.710499Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Class Distribution","metadata":{}},{"cell_type":"code","source":"dictionary = train_df['classname'].value_counts().to_dict()\n# visuallize the dictionary as histogram\nplt.figure(figsize=(5,8))\nplt.bar(range(len(dictionary)), dictionary.values(), align='center')\nplt.xticks(range(len(dictionary)), dictionary.keys())\nplt.title('Number of images per class')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:50.713510Z","iopub.execute_input":"2022-07-09T17:57:50.714726Z","iopub.status.idle":"2022-07-09T17:57:50.932373Z","shell.execute_reply.started":"2022-07-09T17:57:50.714687Z","shell.execute_reply":"2022-07-09T17:57:50.931447Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Image Resolution","metadata":{}},{"cell_type":"code","source":"widths, heights = [], []\n\nfor path in tqdm(train_df[\"path\"]):\n    width, height = Image.open(path).size\n    widths.append(width)\n    heights.append(height)\n    \ntrain_df[\"width\"] = widths\ntrain_df[\"height\"] = heights\ntrain_df[\"dimension\"] = train_df[\"width\"] * train_df[\"height\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:57:51.464110Z","iopub.execute_input":"2022-07-09T17:57:51.464476Z","iopub.status.idle":"2022-07-09T17:59:12.620010Z","shell.execute_reply.started":"2022-07-09T17:57:51.464438Z","shell.execute_reply":"2022-07-09T17:59:12.618776Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"def edges_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index()\n    for idx,i in enumerate(np.random.choice(classes_df['path'],2)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        edges = sobel(image)\n        gray_edges=sobel(gray)\n        dimension = edges.shape\n        fig = plt.figure(figsize=(8, 8))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(gray_edges)\n        plt.subplot(2,2,2)\n        plt.imshow(edges[:dimension[0],:dimension[1],0], cmap=\"gray\")\n        plt.subplot(2,2,3)\n        plt.imshow(edges[:dimension[0],:dimension[1],1], cmap='gray')\n        plt.subplot(2,2,4)\n        plt.imshow(edges[:dimension[0],:dimension[1],2], cmap='gray')\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:59:12.622480Z","iopub.execute_input":"2022-07-09T17:59:12.624039Z","iopub.status.idle":"2022-07-09T17:59:12.637478Z","shell.execute_reply.started":"2022-07-09T17:59:12.623993Z","shell.execute_reply":"2022-07-09T17:59:12.636259Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    edges_images_gray(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:59:12.639038Z","iopub.execute_input":"2022-07-09T17:59:12.639555Z","iopub.status.idle":"2022-07-09T17:59:25.427282Z","shell.execute_reply.started":"2022-07-09T17:59:12.639509Z","shell.execute_reply":"2022-07-09T17:59:25.426402Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def corners_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index()\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        corners_gray = cv2.goodFeaturesToTrack(gray, maxCorners=50, qualityLevel=0.02, minDistance=20)\n        corners_gray = np.float32(corners_gray)\n        for item in corners_gray:\n            x, y = item[0]\n            cv2.circle(image, (int(x), int(y)), 6, (0, 255, 0), -1)\n        fig = plt.figure(figsize=(16, 16))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(image, cmap=\"BuGn\")\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:59:25.429892Z","iopub.execute_input":"2022-07-09T17:59:25.430643Z","iopub.status.idle":"2022-07-09T17:59:25.441208Z","shell.execute_reply.started":"2022-07-09T17:59:25.430603Z","shell.execute_reply":"2022-07-09T17:59:25.440315Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    corners_images_gray(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:59:25.442636Z","iopub.execute_input":"2022-07-09T17:59:25.443536Z","iopub.status.idle":"2022-07-09T17:59:37.161360Z","shell.execute_reply.started":"2022-07-09T17:59:25.443500Z","shell.execute_reply":"2022-07-09T17:59:37.160379Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def sift_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index()\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        sift = cv2.SIFT_create()\n        kp, des = sift.detectAndCompute(gray, None)\n        kp_img = cv2.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n        fig = plt.figure(figsize=(16, 16))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(kp_img, cmap=\"viridis\")\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:59:37.162884Z","iopub.execute_input":"2022-07-09T17:59:37.163489Z","iopub.status.idle":"2022-07-09T17:59:37.173678Z","shell.execute_reply.started":"2022-07-09T17:59:37.163449Z","shell.execute_reply":"2022-07-09T17:59:37.172624Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    sift_images_gray(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:59:37.175303Z","iopub.execute_input":"2022-07-09T17:59:37.176128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Augmentation","metadata":{}},{"cell_type":"code","source":"def plot_augimages(paths, datagen):\n    plt.figure(figsize = (14,28))\n    plt.suptitle('Augmented Images')\n    \n    midx = 0\n    for path in paths:\n        data = Image.open(path)\n        data = data.resize((224,224))\n        samples = np.expand_dims(data, 0)\n        it = datagen.flow(samples, batch_size=1)\n    \n        # Show Original Image\n        plt.subplot(10,5, midx+1)\n        plt.imshow(data)\n        plt.axis('off')\n    \n        # Show Augmented Images\n        for idx, i in enumerate(range(4)):\n            midx += 1\n            plt.subplot(10,5, midx+1)\n            \n            batch = it.next()\n            image = batch[0].astype('uint8')\n            plt.imshow(image)\n            plt.axis('off')\n        midx += 1\n    \n    plt.tight_layout()\n    plt.show()\n\n    \ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest'\n) \n\nplot_augimages(np.random.choice(train_df['path'],10), datagen)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:14:58.898206Z","iopub.execute_input":"2022-07-09T18:14:58.898576Z","iopub.status.idle":"2022-07-09T18:15:03.208797Z","shell.execute_reply.started":"2022-07-09T18:14:58.898543Z","shell.execute_reply":"2022-07-09T18:15:03.200535Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"y_count=len(train_df['classname'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:37.012540Z","iopub.execute_input":"2022-07-09T18:34:37.013143Z","iopub.status.idle":"2022-07-09T18:34:37.019475Z","shell.execute_reply.started":"2022-07-09T18:34:37.013105Z","shell.execute_reply":"2022-07-09T18:34:37.018438Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Dense Model","metadata":{}},{"cell_type":"code","source":"X, y = train_df[['path', 'classname']], train_df['classname']","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:39.115933Z","iopub.execute_input":"2022-07-09T18:34:39.116300Z","iopub.status.idle":"2022-07-09T18:34:39.125288Z","shell.execute_reply.started":"2022-07-09T18:34:39.116266Z","shell.execute_reply":"2022-07-09T18:34:39.123987Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:39.468820Z","iopub.execute_input":"2022-07-09T18:34:39.469177Z","iopub.status.idle":"2022-07-09T18:34:39.481995Z","shell.execute_reply.started":"2022-07-09T18:34:39.469145Z","shell.execute_reply":"2022-07-09T18:34:39.480806Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# X_train_ = \n\n# X_train_ = X_train.reshape(X_train.shape[0], 64*64*3)\n# X_test_ = X_test.reshape(X_test.shape[0], 64*64*3)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:39.888949Z","iopub.execute_input":"2022-07-09T18:34:39.890059Z","iopub.status.idle":"2022-07-09T18:34:39.894618Z","shell.execute_reply.started":"2022-07-09T18:34:39.890013Z","shell.execute_reply":"2022-07-09T18:34:39.893383Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"dense_model = Sequential()\ndense_model.add(Dense(512, input_shape=(64,64, 3), activation='relu'))\ndense_model.add(Dense(256, activation='relu'))\ndense_model.add(Flatten())\ndense_model.add(Dense(y_count, activation='softmax'))\ndense_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\ndense_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:40.441912Z","iopub.execute_input":"2022-07-09T18:34:40.442547Z","iopub.status.idle":"2022-07-09T18:34:40.503257Z","shell.execute_reply.started":"2022-07-09T18:34:40.442510Z","shell.execute_reply":"2022-07-09T18:34:40.501081Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train_generator_custom_model = datagen.flow_from_dataframe(\n        X_train,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(64*64,1),  # All images will be resized to 150x150\n        batch_size=40,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\nval_generator_custom_model = datagen.flow_from_dataframe(\n        X_test,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(64*64,1),  # All images will be resized to 150x150\n        batch_size=40,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\n\n# We can't use this memory friendly approach with Dense layers directly.","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:44.471767Z","iopub.execute_input":"2022-07-09T18:34:44.472133Z","iopub.status.idle":"2022-07-09T18:34:53.497310Z","shell.execute_reply.started":"2022-07-09T18:34:44.472102Z","shell.execute_reply":"2022-07-09T18:34:53.496326Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def path_to_tensor(img_path):\n    # loads RGB image as PIL.Image.Image type\n    img = load_img(img_path, target_size=(64, 64))\n    x = img_to_array(img)\n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n    return np.vstack(list_of_tensors)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:58.042693Z","iopub.execute_input":"2022-07-09T18:34:58.043052Z","iopub.status.idle":"2022-07-09T18:34:58.049663Z","shell.execute_reply.started":"2022-07-09T18:34:58.043021Z","shell.execute_reply":"2022-07-09T18:34:58.048461Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:58.397176Z","iopub.execute_input":"2022-07-09T18:34:58.398734Z","iopub.status.idle":"2022-07-09T18:34:58.411050Z","shell.execute_reply.started":"2022-07-09T18:34:58.398684Z","shell.execute_reply":"2022-07-09T18:34:58.410034Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"train_tensors = paths_to_tensor(X_train['path']).astype('float32')/255 - 0.5","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:34:59.207503Z","iopub.execute_input":"2022-07-09T18:34:59.208562Z","iopub.status.idle":"2022-07-09T18:36:21.147964Z","shell.execute_reply.started":"2022-07-09T18:34:59.208513Z","shell.execute_reply":"2022-07-09T18:36:21.146911Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"val_tensors = paths_to_tensor(X_test['path']).astype('float32')/255 - 0.5","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:36:21.150019Z","iopub.execute_input":"2022-07-09T18:36:21.150391Z","iopub.status.idle":"2022-07-09T18:36:41.730656Z","shell.execute_reply.started":"2022-07-09T18:36:21.150343Z","shell.execute_reply":"2022-07-09T18:36:41.729682Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"labels = y_train\nlabels = [x.split('c')[-1] for x in labels]\nlabels = to_categorical(labels)\n\nvlabels = y_test\nvlabels = [x.split('c')[-1] for x in vlabels]\nvlabels = to_categorical(vlabels)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:36:41.732086Z","iopub.execute_input":"2022-07-09T18:36:41.732690Z","iopub.status.idle":"2022-07-09T18:36:41.753939Z","shell.execute_reply.started":"2022-07-09T18:36:41.732651Z","shell.execute_reply":"2022-07-09T18:36:41.753055Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"X_train_ = datagen.flow(train_tensors, labels, batch_size=20)\nX_test_ = datagen.flow(val_tensors, vlabels, batch_size=20)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:36:41.756457Z","iopub.execute_input":"2022-07-09T18:36:41.756812Z","iopub.status.idle":"2022-07-09T18:36:41.762506Z","shell.execute_reply.started":"2022-07-09T18:36:41.756776Z","shell.execute_reply":"2022-07-09T18:36:41.760821Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"history_custom_model = dense_model.fit(\n      X_train_,\n      epochs=20,\n      steps_per_epoch=20\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T16:57:53.553551Z","iopub.execute_input":"2022-07-09T16:57:53.553938Z","iopub.status.idle":"2022-07-09T16:58:16.547658Z","shell.execute_reply.started":"2022-07-09T16:57:53.553903Z","shell.execute_reply":"2022-07-09T16:58:16.546654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convolutional Model","metadata":{}},{"cell_type":"code","source":"cnn_model = Sequential()\n\n## CNN 1\ncnn_model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64, 64, 3)))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Convolution2D(32,(3,3),activation='relu',padding='same'))\ncnn_model.add(BatchNormalization(axis = 3))\ncnn_model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\ncnn_model.add(Dropout(0.3))\n\n## Output\ncnn_model.add(Flatten())\ncnn_model.add(Dense(512,activation='relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Dropout(0.5))\ncnn_model.add(Dense(128,activation='relu'))\ncnn_model.add(Dropout(0.25))\ncnn_model.add(Dense(10,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:04:55.145477Z","iopub.execute_input":"2022-07-09T17:04:55.145835Z","iopub.status.idle":"2022-07-09T17:04:55.241053Z","shell.execute_reply.started":"2022-07-09T17:04:55.145803Z","shell.execute_reply":"2022-07-09T17:04:55.240156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_cnn_model = datagen.flow_from_dataframe(\n        X_train,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(64, 64),  # All images will be resized to 150x150\n        batch_size=40,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\nval_generator_cnn_model = datagen.flow_from_dataframe(\n        X_test,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(64, 64),  # All images will be resized to 150x150\n        batch_size=40,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:04:55.391258Z","iopub.execute_input":"2022-07-09T17:04:55.391555Z","iopub.status.idle":"2022-07-09T17:05:03.252411Z","shell.execute_reply.started":"2022-07-09T17:04:55.391528Z","shell.execute_reply":"2022-07-09T17:05:03.251466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-09T17:05:03.254431Z","iopub.execute_input":"2022-07-09T17:05:03.254797Z","iopub.status.idle":"2022-07-09T17:05:03.264955Z","shell.execute_reply.started":"2022-07-09T17:05:03.25476Z","shell.execute_reply":"2022-07-09T17:05:03.263947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_custom_model = cnn_model.fit(\n      train_generator_custom_model,\n     validation_data=val_generator_custom_model,\n      steps_per_epoch=100,\n      epochs=70,\n      verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transfer Learning","metadata":{}},{"cell_type":"code","source":"vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(560,560,3))\nvgg19.trainable = False\nx = GlobalAveragePooling2D()(vgg19.output)\npredictions = Dense(y_count, activation='softmax')(x)\nmodel_vgg19 = Model(inputs = vgg19.input, outputs = predictions)\nmodel_vgg19.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:36:41.763819Z","iopub.execute_input":"2022-07-09T18:36:41.764345Z","iopub.status.idle":"2022-07-09T18:36:42.126099Z","shell.execute_reply.started":"2022-07-09T18:36:41.764306Z","shell.execute_reply":"2022-07-09T18:36:42.125084Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model_vgg19.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nrlrp_vgg19 = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.01,patience=2,verbose=2,mode=\"auto\",min_delta=0.0001,cooldown=0,min_lr=0)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:36:42.127452Z","iopub.execute_input":"2022-07-09T18:36:42.128249Z","iopub.status.idle":"2022-07-09T18:36:42.141644Z","shell.execute_reply.started":"2022-07-09T18:36:42.128207Z","shell.execute_reply":"2022-07-09T18:36:42.140653Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"train_generator_vgg_19 = datagen.flow_from_dataframe(\n        X_train,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(560, 560),  # All images will be resized to 150x150\n        batch_size=16,\n        class_mode=\"categorical\",\n        shuffle=True,\n        preprocessing_function=preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:36:42.143523Z","iopub.execute_input":"2022-07-09T18:36:42.144097Z","iopub.status.idle":"2022-07-09T18:36:46.231491Z","shell.execute_reply.started":"2022-07-09T18:36:42.144057Z","shell.execute_reply":"2022-07-09T18:36:46.230467Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"val_generator_vgg_19 = datagen.flow_from_dataframe(\n        X_test,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(560, 560),  # All images will be resized to 150x150\n        batch_size=16,\n        class_mode=\"categorical\",\n        shuffle=True,\n        preprocessing_function=preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:43:35.885714Z","iopub.execute_input":"2022-07-09T18:43:35.886373Z","iopub.status.idle":"2022-07-09T18:43:37.605233Z","shell.execute_reply.started":"2022-07-09T18:43:35.886334Z","shell.execute_reply":"2022-07-09T18:43:37.604184Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"history_vgg19 = model_vgg19.fit(\n      train_generator_vgg_19,\n     validation_data=val_generator_vgg_19,\n      epochs=2,\n      callbacks = [rlrp_vgg19],\n      verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T18:43:40.773978Z","iopub.execute_input":"2022-07-09T18:43:40.774329Z","iopub.status.idle":"2022-07-09T19:18:06.996088Z","shell.execute_reply.started":"2022-07-09T18:43:40.774297Z","shell.execute_reply":"2022-07-09T19:18:06.991625Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## Kernel Visuallization","metadata":{}},{"cell_type":"code","source":"dict_class = {'c0':0, 'c1':1, 'c2': 2, 'c3': 3, 'c4': 4, 'c5':5, 'c6': 6, 'c7':7, 'c8':8, 'c9':9}\n","metadata":{"execution":{"iopub.status.busy":"2022-07-09T19:18:12.220236Z","iopub.execute_input":"2022-07-09T19:18:12.220603Z","iopub.status.idle":"2022-07-09T19:18:12.226500Z","shell.execute_reply.started":"2022-07-09T19:18:12.220571Z","shell.execute_reply":"2022-07-09T19:18:12.225183Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def gradcam_visualise(data, model, class_index):\n    explainer = GradCAM()\n    output = explainer.explain(data, model, class_index=class_index)\n    return output\n\ndef activation_visualise(image, model, layers):\n    explainer = ExtractActivations()\n    output = explainer.explain([image], model, layers_name=layers)\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-07-09T19:18:12.613253Z","iopub.execute_input":"2022-07-09T19:18:12.613963Z","iopub.status.idle":"2022-07-09T19:18:12.619475Z","shell.execute_reply.started":"2022-07-09T19:18:12.613924Z","shell.execute_reply":"2022-07-09T19:18:12.618490Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def plot_data_four(class_name, outputs):\n    fig = plt.figure(figsize=(16, 16))\n    plt.suptitle(classes[class_name])\n    plt.subplot(2,2,1)\n    plt.imshow(outputs[0])\n    plt.subplot(2,2,2)\n    plt.imshow(outputs[1])\n    plt.subplot(2,2,3)\n    plt.imshow(outputs[2])\n    plt.subplot(2,2,4)\n    plt.imshow(outputs[3])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T19:18:13.042025Z","iopub.execute_input":"2022-07-09T19:18:13.042892Z","iopub.status.idle":"2022-07-09T19:18:13.050958Z","shell.execute_reply.started":"2022-07-09T19:18:13.042845Z","shell.execute_reply":"2022-07-09T19:18:13.049950Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def grad_cam(model, df_exp, class_name, class_index, image_size):\n    output_data = []\n    classes_df = df_exp[df_exp['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        image = cv2.resize(image, image_size)\n        data = ([image], None)\n        output = gradcam_visualise(data, model, class_index)\n        output_data.append(output)\n    plot_data_four(class_name, output_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T19:18:13.560141Z","iopub.execute_input":"2022-07-09T19:18:13.560816Z","iopub.status.idle":"2022-07-09T19:18:13.567668Z","shell.execute_reply.started":"2022-07-09T19:18:13.560780Z","shell.execute_reply":"2022-07-09T19:18:13.566483Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def activations_model(model, df_exp, class_name, layers, image_size):\n    output_data = []\n    classes_df = df_exp[df_exp['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        image = cv2.resize(image, image_size)\n        image = tf.expand_dims(image, axis=0)\n        output = activation_visualise([image], model, layers)\n        output_data.append(output)\n    plot_data_four(class_name, output_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T19:18:14.006501Z","iopub.execute_input":"2022-07-09T19:18:14.007467Z","iopub.status.idle":"2022-07-09T19:18:14.015434Z","shell.execute_reply.started":"2022-07-09T19:18:14.007405Z","shell.execute_reply":"2022-07-09T19:18:14.014138Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"for class_name in X_test['classname'].unique():\n    grad_cam(model_vgg19, X_test, class_name, dict_class[class_name], (560,560))","metadata":{"execution":{"iopub.status.busy":"2022-07-09T19:18:14.884124Z","iopub.execute_input":"2022-07-09T19:18:14.884793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}